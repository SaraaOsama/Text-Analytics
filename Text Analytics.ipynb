{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b632881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01a4d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d65d5e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "766a6677",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"Restaurant_Reviews.csv\"\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ce5623d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Liked\n",
       "0                           Wow... Loved this place.   Yes\n",
       "1                                 Crust is not good.    No\n",
       "2          Not tasty and the texture was just nasty.    No\n",
       "3  Stopped by during the late May bank holiday of...   Yes\n",
       "4  The selection on the menu was great and so wer...   Yes"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "002d0c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Mina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ad27f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.discard(\"not\")\n",
    "    return [word for word in tokens if word.isalnum() and word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db2db385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[wow, loved, place]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[crust, not, good]</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[not, tasty, texture, nasty]</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[stopped, late, may, bank, holiday, rick, stev...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[selection, menu, great, prices]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Liked\n",
       "0                                [wow, loved, place]   Yes\n",
       "1                                 [crust, not, good]    No\n",
       "2                       [not, tasty, texture, nasty]    No\n",
       "3  [stopped, late, may, bank, holiday, rick, stev...   Yes\n",
       "4                   [selection, menu, great, prices]   Yes"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Review\"] = df[\"Review\"].apply(tokenize_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15f0b956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.21.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (63.4.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.64.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\mina\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mina\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f6b833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_dataframe(df):\n",
    "    # Load spaCy model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Initialize an empty list to store lemmatized words\n",
    "    lemmatized_words = []\n",
    "\n",
    "    # Process each row of the DataFrame\n",
    "    for row in df[\"Review\"]:\n",
    "        # Initialize an empty list to store lemmatized words for the current row\n",
    "        lemmatized_row = []\n",
    "        # Concatenate all words from the current row into a single sentence\n",
    "        sentence = ' '.join(row)\n",
    "        # Process the sentence using spaCy\n",
    "        doc = nlp(sentence)\n",
    "        # Iterate over tokens and append lemmatized words to the list\n",
    "        for token in doc:\n",
    "            lemmatized_row.append(token.lemma_)\n",
    "        # Append lemmatized words for the current row to the list of lemmatized words\n",
    "        lemmatized_words.append(lemmatized_row)\n",
    "\n",
    "    # Store lemmatized words back into the DataFrame\n",
    "    df['Review'] = lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a8b102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15232914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[wow, love, place]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[crust, not, good]</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[not, tasty, texture, nasty]</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[stop, late, may, bank, holiday, rick, steve, ...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[selection, menu, great, price]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Liked\n",
       "0                                 [wow, love, place]   Yes\n",
       "1                                 [crust, not, good]    No\n",
       "2                       [not, tasty, texture, nasty]    No\n",
       "3  [stop, late, may, bank, holiday, rick, steve, ...   Yes\n",
       "4                    [selection, menu, great, price]   Yes"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6b98066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hena hanrag3 el tokens tani eli et3amalaha separate fel preprocessing l string kamel tani\n",
    "df['Processed_Review'] = df['Review'].apply(lambda x: ' '.join(x))  # x tokens concatenate to string with spaces in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83f2ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ha3ml initialize lel vectorizer eli bi convert el text documents into a matrix of token counts.\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f06ae409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform btdrs el vocabulary men df['Processed_Review']\n",
    "# w bt7awelha le matrix: kol row = document, kol column = kelma. El value = 3dad zhour el kelma fel document.\n",
    "X_bow = vectorizer.fit_transform(df['Processed_Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ec13964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding with Word2Vec\n",
    "\n",
    "# Create a list of token lists for Word2Vec training\n",
    "token_lists = df['Review'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64a1c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_size = The dimensionality of the word vectors.\n",
    "# window = Bnaftared 3adad el kalmat eli mawgoda fel sentence 3ashn tb2a dem el context bta3na\n",
    "# min_count = 2a2al 3adad marra eli kelma mawgoda fel kelma 3ashn t3mlha vector\n",
    "# workers = 3ashn y3ml parallel processing fel training (faster training time)\n",
    "model_w2v = Word2Vec(sentences=token_lists, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97f95bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 3ashan a3ml average vector lel document bta3t el words eli mawgoda\n",
    "def document_vector(word_list, model):\n",
    "    # remove out-of-vocabulary words\n",
    "    word_list = [word for word in word_list if word in model.wv.index_to_key]\n",
    "    if len(word_list) == 0:\n",
    "        # harag3 vector mn 0 3ashn mafish kelma sa7 mawgoda fel model\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        # harag3 el average vector bta3t el words eli mawgoda fel word_list\n",
    "        return np.mean(model.wv[word_list], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc29de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row of the DataFrame\n",
    "df['Document_Vector_filter'] = df['Review'].apply(lambda x: document_vector(x, model_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38c368b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of vectors into a 2D array\n",
    "X_w2v = np.array(df['Document_Vector_filter'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cb8e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X_bow, df['Liked'], test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e98913d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train SVM classifier with Bag-of-Words features\n",
    "svm_bow = SVC(kernel='linear')\n",
    "svm_bow.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2656f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "y_pred_bow = svm_bow.predict(X_test_bow)\n",
    "accuracy_bow = accuracy_score(y_test, y_pred_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "70330884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Bag Of Words Accuracy:  93.69369369369369 %\n",
      "Bag Of Words Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.92      0.96      0.94       224\n",
      "         Yes       0.95      0.92      0.94       220\n",
      "\n",
      "    accuracy                           0.94       444\n",
      "   macro avg       0.94      0.94      0.94       444\n",
      "weighted avg       0.94      0.94      0.94       444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# el accuracy for the Bag Word\n",
    "print('\\n')\n",
    "print(\"Bag Of Words Accuracy: \", accuracy_bow * 100, \"%\")\n",
    "print(\"Bag Of Words Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b030acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the SVM  on W2V \"Word 2 vectors \"\n",
    "\n",
    "# Train Logistic Regression classifier with Word2Vec embeddings\n",
    "logreg_w2v = LogisticRegression(max_iter=500)\n",
    "logreg_w2v.fit(X_train_bow, y_train)\n",
    "\n",
    "y_pred_logreg_w2v = logreg_w2v.predict(X_test_bow)\n",
    "accuracy_logreg_w2v = accuracy_score(y_test, y_pred_logreg_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eab85b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Logistic Regression with Word2Vec Accuracy:  91.66666666666666 %\n",
      "Logistic Regression with Word2Vec Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.90      0.94      0.92       224\n",
      "         Yes       0.93      0.90      0.91       220\n",
      "\n",
      "    accuracy                           0.92       444\n",
      "   macro avg       0.92      0.92      0.92       444\n",
      "weighted avg       0.92      0.92      0.92       444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "print(\"Logistic Regression with Word2Vec Accuracy: \", accuracy_logreg_w2v * 100, \"%\")\n",
    "print(\"Logistic Regression with Word2Vec Classification Report: \")\n",
    "print(classification_report(y_test, y_pred_logreg_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f7dfb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize NLTK sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "24a32e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "\n",
    "    sentiment = 1 if scores['pos'] > 0 else 0\n",
    "\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cd577a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply get_sentiment function\n",
    "df['scores'] = df['Processed_Review'].apply(analyzer.polarity_scores)\n",
    "df['sentiment'] = df['Processed_Review'].apply(get_sentiment)\n",
    "df['Liked'] = df['Liked'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e00eb086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matirx : \n",
      "[[906 213]\n",
      " [245 856]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "print(\"Confusion Matirx : \")\n",
    "print(confusion_matrix(df['Liked'], df['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb1ffe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1119\n",
      "           1       0.80      0.78      0.79      1101\n",
      "\n",
      "    accuracy                           0.79      2220\n",
      "   macro avg       0.79      0.79      0.79      2220\n",
      "weighted avg       0.79      0.79      0.79      2220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(df['Liked'], df['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dbc0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20bd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f4d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
